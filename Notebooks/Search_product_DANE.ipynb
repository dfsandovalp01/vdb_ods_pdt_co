{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# %pip install gradio\n",
    "# # %pip install sentence_transformers\n",
    "# %pip install chromadb\n",
    "# # %pip install zipfile\n",
    "# %pip install pdfplumber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura VDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniel B\\miniconda3\\envs\\nlp_base\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:141: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n",
      "c:\\Users\\Daniel B\\miniconda3\\envs\\nlp_base\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "c:\\Users\\Daniel B\\miniconda3\\envs\\nlp_base\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "\n",
    "embeddings_st = SentenceTransformerEmbeddings(\n",
    "    # model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "    model_name=\"hackathon-pln-es/paraphrase-spanish-distilroberta\",\n",
    "    # model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "    # device=\"cuda\",\n",
    "    model_kwargs={\"device\":\"cpu\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniel B\\miniconda3\\envs\\nlp_base\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:141: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 0.4. An updated version of the class exists in the langchain-chroma package and should be used instead. To use it run `pip install -U langchain-chroma` and import as `from langchain_chroma import Chroma`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "import os\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "vdb_dir = os.path.join(current_dir, os.pardir, \"data\", \"vdb\", \"chromaPdtGob_pSpDroberta\")\n",
    "# print(os.path.exists(data_dir))\n",
    "vectorstore_chroma = Chroma(\n",
    "    persist_directory=vdb_dir,#NOMBRE_INDICE_CHROMA,\n",
    "    embedding_function=embeddings_st\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "from PIL import Image\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "\n",
    "dir_temp_img = os.path.join(os.getcwd(), os.pardir, \"data\", \"temp\", \"img\")\n",
    "dir_temp_pdf = os.path.join(os.getcwd(), os.pardir, \"data\", \"temp\", \"pdf\")\n",
    "\n",
    "def readPageVW(docname, page, dir_temp_img=dir_temp_img):\n",
    "  page_view = None\n",
    "  with pdfplumber.open(docname) as pdf:\n",
    "    page_view = pdf.pages[page-1].to_image()\n",
    "    # dir = os.path.join(os.getcwd(), os.pardir, \"data\", \"temp\", \"img\")\n",
    "    # dir = f\"/content/images\"\n",
    "    # dir = dir.replace('Departamentos/','')#.replace('Departamentos/','')\n",
    "     # Guarda la imagen como .png\n",
    "    os.makedirs(dir_temp_img,exist_ok=True)\n",
    "    page_view.save(f\"{dir_temp_img}/page_{page}_doc_{docname.replace('Departamentos/','').replace('.pdf','.png')}\")\n",
    "  return page_view\n",
    "\n",
    "def readZip(idDoc,page,dir='Departamentos'):\n",
    "# def readZip(idDoc,page,dir=os.path.join(os.getcwd(), \"Departamentos\")):\n",
    "# def readZip(idDoc,page,dir_temp_pdf=dir_temp_pdf):\n",
    "  # for _ in [f for f in os.listdir(dir) if f.endswith('.pdf')]:\n",
    "  #     os.remove(os.path.join(dir, _))\n",
    "  docname = f'{dir}/{idDoc}.pdf'\n",
    "  # docname = os.path.join(dir, f'{idDoc}.pdf')\n",
    "  # print(f'docname: {docname}')\n",
    "  if os.path.exists(docname):\n",
    "      # os.remove(docname)\n",
    "      page_view = readPageVW(docname, page)\n",
    "      # print(f\"{} ha sido eliminado.\")\n",
    "  else:\n",
    "    # print(f\"El archivo {i} no existe.\")\n",
    "    pages = []\n",
    "    bdl_corpus = pd.DataFrame()\n",
    "    page_view = None\n",
    "    # ruta = '/content/drive/MyDrive/Automatizacion ODS 11a1/Pruebas/Departamentos/datos/Departamentos.zip'\n",
    "    ruta = os.path.join(os.getcwd(), os.pardir, \"data\", \"comprimido\", \"Departamentos.zip\")\n",
    "    # Abrir el archivo .zip\n",
    "    with zipfile.ZipFile(ruta, 'r') as zip_ref:\n",
    "      # Listar el contenido del .zip\n",
    "      lista_archivos = zip_ref.namelist()\n",
    "      # print(lista_archivos)\n",
    "\n",
    "      try:\n",
    "        # i = i.replace('Departamentos/','')\n",
    "        zip_ref.extract(docname)\n",
    "        page_view = readPageVW(docname, page)\n",
    "\n",
    "      except Exception as e:\n",
    "        print(f'Error:  {e}')\n",
    "        pass\n",
    "  \n",
    "      \n",
    "  return page_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#departamentos\n",
    "lista_archivos_pdf = ['05.pdf', '08.pdf', '15.pdf', '17.pdf', '18.pdf', '19.pdf', '20.pdf', '23.pdf', '25.pdf', '27.pdf', '41.pdf', '52.pdf', '54.pdf', '63.pdf', '66.pdf',\n",
    " '68.pdf', '73.pdf', '76.pdf', '81.pdf', '85.pdf', '86.pdf', '88.pdf', '91.pdf', '94.pdf', '95.pdf', '97.pdf', '99.pdf']\n",
    "# data_dir = os.path.join(os.getcwd(), os.pardir, \"data\")\n",
    "# print(data_dir)\n",
    "codigos_dane = pd.read_csv(os.path.join(os.getcwd(), os.pardir, \"data\", \"Tabla_codigos_Dane.txt\"), sep='|', dtype=str)\n",
    "codigoDepartamentoPdf = [_.replace('.pdf','') for _ in lista_archivos_pdf]\n",
    "codigos_dane_dpto = codigos_dane.groupby(['CodigoDepartamento', 'NombreDepartamento']).agg({'CodigoMunicipio':'count'}).reset_index()\n",
    "codigos_dane_dpto = codigos_dane_dpto[codigos_dane_dpto.CodigoDepartamento.isin(codigoDepartamentoPdf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "\n",
    "def search(query,filter,dpto,rank,dir_temp_img=dir_temp_img):\n",
    "  # query = \"proyecciones de poblacion\"\n",
    "  # doc1 = None\n",
    "  for _ in [f for f in os.listdir('Departamentos') if f.endswith('.pdf')]:\n",
    "      os.remove(os.path.join(os.getcwd(), 'Departamentos', _))\n",
    "  if os.path.exists(dir_temp_img):\n",
    "    for _ in [f for f in os.listdir(dir_temp_img) if f.endswith('.png')]:\n",
    "      os.remove(f'{dir_temp_img}/{_}')\n",
    "    # print(f\"{i} ha sido eliminado.\")\n",
    "  if filter == \"Filtro\":\n",
    "    doc1 = codigos_dane_dpto[codigos_dane_dpto.NombreDepartamento == dpto].reset_index(drop=True).loc[0,'CodigoDepartamento']\n",
    "    doc1 = f'{doc1}.pdf'\n",
    "    docs = vectorstore_chroma.similarity_search_with_score(query, k=rank, filter={\"source\": doc1})  # .unique()\n",
    "  else:\n",
    "    docs = vectorstore_chroma.similarity_search_with_score(query, k=rank)\n",
    "\n",
    "\n",
    "\n",
    "  # scores = [round(1 - doc[1]/100,2) for doc in docs ]\n",
    "  scores = [round(doc[1],2) for doc in docs ]\n",
    "  text = [doc[0].page_content for doc in docs ]\n",
    "  page = [doc[0].metadata['page'] for doc in docs ]\n",
    "  source = [doc[0].metadata['source'] for doc in docs ]\n",
    "  idDN = [doc[0].metadata['source'].replace('.pdf','') for doc in docs ]\n",
    "\n",
    "  df = pd.DataFrame({\n",
    "    'source': source,\n",
    "    'page': page,\n",
    "    'scores': scores,\n",
    "    'text': text,\n",
    "    'idDANE': idDN\n",
    "    })\n",
    "\n",
    "\n",
    "  df = df.merge(codigos_dane_dpto[['CodigoDepartamento','NombreDepartamento']], 'left', left_on='idDANE', right_on='CodigoDepartamento')\n",
    "  imgs = []\n",
    "  for index, row in df.iterrows():\n",
    "    # imgs.append(readZip(row['idDANE'], row['page']))\n",
    "    readZip(row['idDANE'], row['page'])\n",
    "  png_files = [f for f in os.listdir(dir_temp_img) if f.endswith('.png')]\n",
    "  for file in png_files:\n",
    "    image_path = os.path.join(dir_temp_img, file)\n",
    "    image = Image.open(image_path)\n",
    "    image = [image, file]\n",
    "    imgs.append(image)\n",
    "    # print(row['idDANE'], row['NombreDepartamento'])\n",
    "\n",
    "  df[['source','page']] = df[['source','page']].astype(str)\n",
    "  df['LABELS'] = df['source'] + '-' + df['page']\n",
    "\n",
    "  return df[['idDANE','page','scores','text','NombreDepartamento']], imgs\n",
    "\n",
    "# pr = search('desarrollo equilibrado asentamientos, pueblos, ciudades','no filtro','x',10)\n",
    "# Define possible genres\n",
    "# clientes = clients.tolist()\n",
    "\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=search,\n",
    "    inputs=[\n",
    "        gr.Textbox(lines=5, placeholder=\"Escribe aquí tu consulta...\", label=\"Consulta\"),\n",
    "        gr.Radio([\"Filtro\", \"Sin filtro\"]),\n",
    "        # gr.Textbox(lines=1, placeholder=\"Doc Name\", label=\"Doc Name\"),\n",
    "        gr.Dropdown(choices=list(codigos_dane_dpto.NombreDepartamento), label=\"Departamento\"),\n",
    "        # gr.Slider(minimum=1, maximum=10, value=5, label=\"Puntuación mínima\"),\n",
    "        gr.Number(minimum=1, maximum=15, value=10, label=\"Número de resultados\")\n",
    "\n",
    "    ],\n",
    "    outputs=[gr.Dataframe(type=\"pandas\", label=\"Resultados\"), gr.Gallery(\n",
    "        label=\"Generated images\", show_label=True, elem_id=\"gallery\"\n",
    "    , columns=[2], rows=[5], object_fit=\"contain\", height=\"auto\")],\n",
    "    title=\"PDT Gobernaciones\",\n",
    "    description=\"Analizar PDT.\",\n",
    "    live=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'page': 19, 'source': '17.pdf'}, page_content='desarrollo vigencia'),\n",
       "  25.232271194458008),\n",
       " (Document(metadata={'page': 317, 'source': '23.pdf'}, page_content='actualmente llamado cumplir'),\n",
       "  32.78734588623047),\n",
       " (Document(metadata={'page': 98, 'source': '17.pdf'}, page_content='xx'),\n",
       "  33.443660736083984),\n",
       " (Document(metadata={'page': 166, 'source': '94.pdf'}, page_content='incremento ano respecto vigencia'),\n",
       "  36.31009292602539),\n",
       " (Document(metadata={'page': 23, 'source': '15.pdf'}, page_content='territorial ultima vigencia'),\n",
       "  38.14746856689453),\n",
       " (Document(metadata={'page': 256, 'source': '17.pdf'}, page_content='xxx'),\n",
       "  38.73954391479492),\n",
       " (Document(metadata={'page': 36, 'source': '76.pdf'}, page_content='futuras puedan gozar'),\n",
       "  39.09825897216797),\n",
       " (Document(metadata={'page': 287, 'source': '17.pdf'}, page_content='telefonia movil intervenir bienes interes cultural departamento primeros auxilios identificar valorar conservar difundir'),\n",
       "  41.879112243652344),\n",
       " (Document(metadata={'page': 174, 'source': '88.pdf'}, page_content='mano obra nuevo comienzo'),\n",
       "  42.640716552734375),\n",
       " (Document(metadata={'page': 69, 'source': '81.pdf'}, page_content='realicen giro recursos den respuesta numeral articulo ley fin contribuir seguridad creador gestor cultural anterior espera'),\n",
       "  42.85871124267578)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search('desarrollo equilibrado','no','dpto',20,dir_temp_img=dir_temp_img)\n",
    "query = [\"desarrollo \",\"garantizan un desarrollo territorial equilibrado\"]\n",
    "\n",
    "\n",
    "docs = vectorstore_chroma.similarity_search_with_score(query[0], k=10)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with gr.Blocks() as demo:\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            prompt = gr.Textbox(lines=5, placeholder=\"Escribe aquí tu consulta...\", label=\"Consulta\")\n",
    "            gr.Examples([\"desarrollo equilibrado asentamientos, pueblos, ciudades\",\"garantizan un desarrollo territorial equilibrado\"], inputs=[prompt])\n",
    "            filtros = gr.Radio([\"Filtro\", \"Sin filtro\"])\n",
    "            departamento = gr.Dropdown(choices=list(codigos_dane_dpto.NombreDepartamento), label=\"Departamento\")\n",
    "            salidas = gr.Number(minimum=1, maximum=15, value=10, label=\"Número de resultados\")\n",
    "\n",
    "    with gr.Row():\n",
    "        consulta_btn = translate_btn = gr.Button(value=\"Consultar\")\n",
    "\n",
    "    with gr.Row():\n",
    "        tabla = gr.Dataframe(type=\"pandas\", label=\"Resultados\")\n",
    "\n",
    "    # with gr.Row():\n",
    "    #     resol = gr.Slider(minimum=500, maximum=1500, value=100, label=\"Resolución\")\n",
    "\n",
    "    with gr.Row():\n",
    "        galeria = gr.Gallery(label=\"Generated images\", show_label=True, elem_id=\"gallery\", scale=2,object_fit=\"contain\", height=1001)#\"auto\")\n",
    "\n",
    "\n",
    "    translate_btn.click(search, inputs=[prompt, filtros, departamento, salidas], outputs=[tabla, galeria])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo.launch(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "demo.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
